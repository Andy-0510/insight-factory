import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import matplotlib.dates as mdates
import seaborn as sns
import os
import json
import math
import networkx as nx
import re
from pathlib import Path
from wordcloud import WordCloud
import numpy as np
from adjustText import adjust_text
from src.utils import load_json, save_json, latest
from datetime import datetime
from pathlib import Path

### ì¶”ê°€ ì´ë¯¸ì§€ (timeseries_spikes.png, strong_signals_topbar.png, topics_bubble.png)
FIG_DIR = "outputs/fig"
EXPORT_DIR = "outputs/export"

def _ensure_dirs():
    Path(FIG_DIR).mkdir(parents=True, exist_ok=True)
    Path(EXPORT_DIR).mkdir(parents=True, exist_ok=True)

def _safe_read_csv(path, **kwargs):
    try:
        if os.path.exists(path):
            return pd.read_csv(path, **kwargs)
    except Exception:
        pass
    return pd.DataFrame()

def _parse_date(s):
    try:
        return datetime.strptime(str(s), "%Y-%m-%d")
    except Exception:
        try:
            return pd.to_datetime(s)
        except Exception:
            return None

def _savefig(path, tight=True, dpi=160, facecolor="white"):
    if tight:
        plt.tight_layout()
    Path(os.path.dirname(path)).mkdir(parents=True, exist_ok=True)
    plt.savefig(path, dpi=dpi, facecolor=facecolor)
    plt.close()

# 1) timeseries_spikes.png ìƒì„±
def gen_timeseries_spikes(
    daily_json_path="outputs/trend_timeseries.json",
    out_timeseries=f"{FIG_DIR}/timeseries.png",
    out_spikes=f"{FIG_DIR}/timeseries_spikes.png",
    out_spike_csv=f"{EXPORT_DIR}/timeseries_spikes.csv",
    ma_window=7, z_thresh=2.5
):
    _ensure_dirs()
    data = {}
    try:
        with open(daily_json_path, "r", encoding="utf-8") as f:
            data = json.load(f) or {}
    except Exception:
        data = {}

    daily = data.get("daily", [])
    if not daily:
        return

    df = pd.DataFrame(daily)
    if "date" not in df.columns or "count" not in df.columns:
        return
    df["date"] = df["date"].apply(_parse_date)
    df = df.dropna(subset=["date"]).sort_values("date")
    df["count"] = pd.to_numeric(df["count"], errors="coerce").fillna(0)

    # ê¸°ë³¸ ì‹œê³„ì—´
    plt.figure(figsize=(10, 4))
    plt.plot(df["date"], df["count"], label="Daily", color="#2c7be5", alpha=0.85)
    if len(df) >= ma_window:
        df["ma"] = df["count"].rolling(ma_window).mean()
        plt.plot(df["date"], df["ma"], label=f"{ma_window}-day MA", color="#495057")
    plt.title("Daily Articles")
    plt.xlabel("Date"); plt.ylabel("Count")
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter("%m-%d"))
    plt.legend(loc="upper left")
    _savefig(out_timeseries)

    # ìŠ¤íŒŒì´í¬ íƒì§€
    if df["count"].std() > 0:
        z = (df["count"] - df["count"].mean()) / df["count"].std()
        df["z"] = z
        spikes = df.loc[df["z"] >= z_thresh].copy()
    else:
        spikes = pd.DataFrame()

    # ìŠ¤íŒŒì´í¬ í”Œë¡¯
    plt.figure(figsize=(10, 4))
    plt.plot(df["date"], df["count"], color="#2c7be5", alpha=0.6)
    if not spikes.empty:
        plt.scatter(spikes["date"], spikes["count"], color="#d92550", s=40, label=f"Spikes (z>={z_thresh:.1f})")
        for _, r in spikes.iterrows():
            plt.annotate(r["date"].strftime("%m-%d"), (r["date"], r["count"]), textcoords="offset points", xytext=(0,8), ha="center", fontsize=8)
        plt.legend()
    plt.title("Spikes")
    plt.xlabel("Date"); plt.ylabel("Count")
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter("%m-%d"))
    _savefig(out_spikes)

    # CSV ì €ì¥
    if not spikes.empty:
        out = spikes[["date","count","z"]].copy()
        out["date"] = out["date"].dt.strftime("%Y-%m-%d")
        out.to_csv(out_spike_csv, index=False, encoding="utf-8")

# 2) strong_signals_topbar.png ìƒì„±
def gen_strong_signals_bar(
    csv_path=f"{EXPORT_DIR}/trend_strength.csv",
    out_path=f"{FIG_DIR}/strong_signals_topbar.png",
    topn=15
):
    _ensure_dirs()
    df = _safe_read_csv(csv_path)
    if df.empty:
        return
    term_col = "term" if "term" in df.columns else df.columns[0]
    val_col = "cur" if "cur" in df.columns else df.columns[1]
    df = df.sort_values(val_col, ascending=False).head(topn)

    plt.figure(figsize=(10, 6))
    plt.barh(df[term_col][::-1], df[val_col][::-1], color="#2c7be5")
    plt.title("Strong Signals (Top)")
    plt.xlabel(val_col)
    _savefig(out_path)

# 3) topics_bubble.png ìƒì„±
def gen_topics_bubble(topics_json="outputs/topics.json",
                      out_path=f"{FIG_DIR}/topics_bubble.png",
                      min_bubble=40, jitter=0.01):
    _ensure_dirs()
    try:
        with open(topics_json, "r", encoding="utf-8") as f:
            topics = json.load(f) or {}
    except Exception:
        topics = {}
    tlist = topics.get("topics") or []
    if not tlist:
        return

    xs, ys, ss, labels = [], [], [], []
    for t in tlist:
        # ê´€ëŒ€í•˜ê²Œ ëŒ€ì²´
        interest = t.get("interest", t.get("score", 0))
        positivity = t.get("positive", t.get("sentiment", 0.5))
        activity = t.get("activity", len(t.get("top_words", [])) * 5)

        try:
            x = float(interest or 0)
        except Exception:
            x = 0.0
        try:
            y = float(positivity if positivity is not None else 0.5)
        except Exception:
            y = 0.5
        try:
            s = float(activity or 1) * 10
        except Exception:
            s = 10.0

        # ìµœì†Œ ë²„ë¸” í¬ê¸° ë³´ì¥ + ê²¹ì¹¨ ì™„í™” ì§€í„°
        s = max(min_bubble, s)
        x += np.random.uniform(-jitter, jitter)
        y += np.random.uniform(-jitter, jitter)

        xs.append(x); ys.append(y); ss.append(s)
        labels.append(t.get("topic_name") or f"topic_{t.get('topic_id')}")

    plt.figure(figsize=(10, 6))
    sc = plt.scatter(xs, ys, s=ss, alpha=0.35, c=ys, cmap="coolwarm", edgecolors="#999999", linewidths=0.5)
    # ë¼ë²¨ì€ ìƒìœ„ 20ê°œë§Œ
    for i, lab in enumerate(labels[:20]):
        plt.annotate(lab, (xs[i], ys[i]), fontsize=8, alpha=0.85)
    plt.colorbar(sc, label="Positivity")
    plt.xlabel("Interest"); plt.ylabel("Positivity")
    plt.title("Topics Bubble Map")
    _savefig(out_path)


### ê¸°ë³¸ ì„¤ì •
def load_data():
    keywords = load_json("outputs/keywords.json", {"keywords": [], "stats": {}})
    topics = load_json("outputs/topics.json", {"topics": []})
    ts = load_json("outputs/trend_timeseries.json", {"daily": []})
    insights = load_json("outputs/trend_insights.json", {"summary": "", "top_topics": [], "evidence": {}})
    opps = load_json("outputs/biz_opportunities.json", {"ideas": []})
    meta_path = latest("data/news_meta_*.json")
    meta_items = load_json(meta_path, []) if meta_path else []
    return keywords, topics, ts, insights, opps, meta_items

def simple_tokenize_ko(text: str):
    toks = re.findall(r"[ê°€-í£A-Za-z0-9]+", text or "")
    toks = [t.lower() for t in toks if len(t) >= 2]
    return toks

def build_docs_from_meta(meta_items):
    docs = []
    for it in meta_items:
        title = (it.get("title") or it.get("title_og") or "").strip()
        desc = (it.get("description") or it.get("description_og") or "").strip()
        doc = (title + " " + desc).strip()
        if doc:
            docs.append(doc)
    return docs

# --- Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ---
def ensure_fonts():
    import matplotlib.font_manager as fm
    
    # ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ Nanum í°íŠ¸ ë˜ëŠ” Noto Sans CJK í°íŠ¸ ê²½ë¡œ íƒìƒ‰
    font_paths = fm.findSystemFonts(fontpaths=None, fontext='ttf')
    nanum_gothic = next((path for path in font_paths if 'NanumGothic' in path), None)
    noto_sans_cjk = next((path for path in font_paths if 'NotoSansKR' in path or 'NotoSansCJK' in path), None)

    font_path = nanum_gothic or noto_sans_cjk
    
    if font_path:
        fm.fontManager.addfont(font_path)
        font_name = fm.FontProperties(fname=font_path).get_name()
        plt.rcParams['font.family'] = font_name
    else:
        # ì ì ˆí•œ í°íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ í°íŠ¸ë¡œ ì„¤ì • (ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥)
        print("[WARN] NanumGothic or NotoSansKR font not found. Please install it for proper Korean display.")
        plt.rcParams['font.family'] = 'sans-serif'
        
    plt.rcParams['axes.unicode_minus'] = False
    print(f"[INFO] Matplotlib font set to: {plt.rcParams['font.family']}")

def apply_plot_style():
    plt.rcParams.update({
        "figure.dpi": 150,
        "savefig.dpi": 150,
        "axes.titlesize": 12,
        "axes.labelsize": 11,
        "xtick.labelsize": 9,
        "ytick.labelsize": 9,
        "legend.fontsize": 9,
        "axes.grid": True,
        "grid.alpha": 0.25,
        "grid.linestyle": "--",
        "grid.linewidth": 0.6,
        "axes.edgecolor": "#999",
        "axes.linewidth": 0.8,
    })


def plot_wordcloud_from_keywords(keywords_obj, out_path="outputs/fig/wordcloud.png"):
    # --- í°íŠ¸ ì„¤ì • ---
    font_paths = fm.findSystemFonts(fontpaths=None, fontext='ttf')
    nanum_gothic = next((p for p in font_paths if 'NanumGothic' in p), None)
    noto_sans_cjk = next((p for p in font_paths if 'NotoSansKR' in p or 'NotoSansCJK' in p), None)
    font_path = nanum_gothic or noto_sans_cjk
    if not font_path:
        print("[WARN] í•œê¸€ í°íŠ¸ ì—†ìŒ. ì˜ì–´ë§Œ í‘œì‹œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # --- ë°ì´í„° ì¤€ë¹„ ---
    items = (keywords_obj or {}).get("keywords", [])
    if not items:
        plt.figure(figsize=(8, 5))
        plt.text(0.5, 0.5, "ì›Œë“œí´ë¼ìš°ë“œ ë°ì´í„° ì—†ìŒ", ha="center", va="center")
        plt.axis("off")
        plt.savefig(out_path, bbox_inches="tight", dpi=150)
        plt.close()
        return

    freqs = {it["keyword"]: max(float(it.get("score", 0)), 0) for it in items[:200] if it.get("keyword")}

    # --- ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ---
    wc = WordCloud(
        width=1600,                   # ì´ë¯¸ì§€ í¬ê¸° í™•ëŒ€ â†’ ê³ í•´ìƒë„
        height=900,
        background_color="white",
        colormap="tab20c",            # ë” ë¶€ë“œëŸ¬ìš´ ì»¬ëŸ¬ë§µ
        font_path=font_path,
        prefer_horizontal=0.8,        # ì„¸ë¡œ/ê°€ë¡œ 80% ë¹„ìœ¨
        relative_scaling=0.4,         # ë‹¨ì–´ í¬ê¸° ë¹„ìœ¨ ì™„í™” â†’ ì‹œê°ì  ê· í˜•
        min_font_size=12,
        max_font_size=None,           # ìë™ ìµœì í™”
        contour_color="#dddddd",      # ìœ¤ê³½ì„  ì¶”ê°€
        contour_width=1.0,
        random_state=42,
        margin=2,                     # ë‹¨ì–´ ê°„ê²© ìµœì†Œí™”
        collocations=False,           # ì¤‘ë³µ ë‹¨ì–´ ê²°í•© ë°©ì§€
        normalize_plurals=False,
        scale=3                       # ê³ ë°€ë„ ë Œë”ë§
    ).generate_from_frequencies(freqs)

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    wc.to_file(out_path)
    print("[INFO] Saved styled wordcloud:", out_path)



def plot_top_keywords(keywords, out_path="outputs/fig/top_keywords.png", topn=15):
    ensure_fonts()
    apply_plot_style()
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    data = keywords.get("keywords", [])[:topn]
    if not data:
        plt.figure(figsize=(8, 5))
        plt.text(0.5, 0.5, "í‚¤ì›Œë“œ ë°ì´í„° ì—†ìŒ", ha="center")
        plt.axis("off")
        plt.savefig(out_path, dpi=150, bbox_inches="tight")
        plt.close()
        return
    labels = [d["keyword"] for d in data][::-1]
    scores = [d["score"] for d in data][::-1]
    plt.figure(figsize=(10, 6))
    sns.barplot(x=scores, y=labels, color="#3b82f6")
    plt.title("Top Keywords")
    plt.xlabel("Score")
    plt.ylabel("")
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()

def plot_topics(topics, out_path="outputs/fig/topics.png", topn_words=6):
    import math
    ensure_fonts()
    apply_plot_style()
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    tps = topics.get("topics", [])
    if not tps:
        plt.figure(figsize=(8, 5))
        plt.text(0.5, 0.5, "í† í”½ ë°ì´í„° ì—†ìŒ", ha="center")
        plt.axis("off")
        plt.savefig(out_path, dpi=150, bbox_inches="tight")
        plt.close()
        return

    k = len(tps)
    cols = 2
    rows = math.ceil(k / cols)
    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))
    axes = axes.flatten() if k > 1 else [axes]

    for i, t in enumerate(tps):
        ax = axes[i]
        words = (t.get("top_words") or [])[:topn_words]
        labels = [str((w.get("word") or "")) for w in words][::-1]
        probs = []
        for w in words[::-1]:
            pw = w.get("prob", 1.0)
            try:
                p = float(pw)
                if p <= 0:
                    p = 1.0
            except Exception:
                p = 1.0
            probs.append(p)

        sns.barplot(x=probs, y=labels, ax=ax, color="#10b981")

        # âœ… ì œëª© ì—…ë°ì´íŠ¸
        topic_id = t.get("topic_id")
        topic_name = t.get("topic_name", f"topic_{topic_id}")
        ax.set_title(f"Topic #{topic_id} ({topic_name})")

        ax.set_xlabel("Weight")
        ax.set_ylabel("")

    for j in range(i + 1, len(axes)):
        axes[j].axis("off")

    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()


def plot_timeseries(ts, out_path="outputs/fig/timeseries.png"):
    import matplotlib.dates as mdates
    from datetime import datetime, timedelta
    ensure_fonts()
    apply_plot_style()
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    daily = ts.get("daily", [])
    if not daily:
        plt.figure(figsize=(10, 5))
        plt.title("Articles per Day (no data)")
        plt.xlabel("Date")
        plt.ylabel("Count")
        plt.tight_layout()
        plt.savefig(out_path, dpi=150, bbox_inches="tight")
        plt.close()
        return
    df = pd.DataFrame(daily).copy()
    df["date"] = pd.to_datetime(df["date"], errors="coerce", utc=False)
    df["count"] = pd.to_numeric(df.get("count", 0), errors="coerce").fillna(0).astype(int)
    df = df.dropna(subset=["date"]).sort_values("date")
    now_year = datetime.now().year
    y_min, y_max = now_year - 3, now_year + 1
    df = df[(df["date"].dt.year >= y_min) & (df["date"].dt.year <= y_max)]
    if df.empty:
        plt.figure(figsize=(10, 5))
        plt.title("Articles per Day (empty after filtering)")
        plt.xlabel("Date")
        plt.ylabel("Count")
        plt.tight_layout()
        plt.savefig(out_path, dpi=150, bbox_inches="tight")
        plt.close()
        return
    df = df.set_index("date")
    full_idx = pd.date_range(df.index.min().normalize(), df.index.max().normalize(), freq="D")
    df = df.reindex(full_idx).fillna(0)
    df.index.name = "date"
    df["count"] = df["count"].astype(int)
    if len(df) == 1:
        d0 = df.index[0]
        y = float(df["count"].iloc[0])
        plt.figure(figsize=(12, 4.5))
        plt.xlim(d0 - timedelta(days=1), d0 + timedelta(days=1))
        ypad = max(1, y * 0.15)
        plt.ylim(0, y + ypad)
        ax = plt.gca()
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y-%m-%d"))
        plt.plot([d0], [y], marker="o", color="#6366f1", label="Daily")
        plt.annotate(f"{int(y)}", (d0, y), textcoords="offset points", xytext=(0, -14), ha="center",
                     fontsize=9, bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="none", alpha=0.7))
        plt.title(f"Articles per Day ({d0.strftime('%Y-%m-%d')})")
        plt.xlabel("Date")
        plt.ylabel("Count")
        plt.legend(loc="upper right")
        plt.grid(alpha=0.25, linestyle="--")
        plt.tight_layout()
        plt.savefig(out_path, dpi=150, bbox_inches="tight")
        plt.close()
        return
    plt.figure(figsize=(12, 4.5))
    ax = plt.gca()
    ax.xaxis.set_major_locator(mdates.AutoDateLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y-%m-%d"))
    plt.plot(df.index, df["count"], marker="o", markersize=3, linewidth=1, color="#6366f1", label="Daily")
    if len(df) >= 7:
        df["ma7"] = df["count"].rolling(window=7, min_periods=1).mean()
        plt.plot(df.index, df["ma7"], linestyle="--", linewidth=2, color="#f43f5e", label="7-day MA")
    plt.title("Articles per Day")
    plt.xlabel("Date")
    plt.ylabel("Count")
    plt.legend(loc="upper right")
    plt.grid(alpha=0.25, linestyle="--")
    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches="tight")
    plt.close()

def plot_keyword_network(keywords, docs, out_path="outputs/fig/keyword_network.png",
                         topn=50, min_cooccur=4, max_edges=40, label_top=25):
    """ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ìƒì„± (PageRank ê¸°ë°˜ ë¼ë²¨ë§ + ì»¤ë®¤ë‹ˆí‹° íƒì§€ ì‹œê°í™” ë²„ì „) """
    from networkx.algorithms import community
    from matplotlib.patches import Patch

    ensure_fonts()
    apply_plot_style()
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    # 1. í‚¤ì›Œë“œ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    keyword_scores = {
        it.get("keyword"): float(it.get("score", 0))
        for it in keywords.get("keywords", [])[:topn]
        if it.get("keyword")
    }

    if not keyword_scores or not docs:
        return {"nodes": 0, "edges": 0}

    # 2. ê³µë™ ì¶œí˜„ ê³„ì‚°
    cooccur = {}
    for doc in docs:
        words_in_doc = set(simple_tokenize_ko(doc)).intersection(keyword_scores.keys())
        words_in_doc = sorted(words_in_doc)
        for i in range(len(words_in_doc)):
            for j in range(i + 1, len(words_in_doc)):
                pair = tuple(sorted((words_in_doc[i], words_in_doc[j])))
                cooccur[pair] = cooccur.get(pair, 0) + 1

    # 3. ìƒìœ„ ì—£ì§€ ì„ íƒ
    edges = sorted(
        [(u, v, w) for (u, v), w in cooccur.items() if w >= min_cooccur],
        key=lambda x: x[2],
        reverse=True
    )[:max_edges]

    # 4. ê·¸ë˜í”„ êµ¬ì„±
    G = nx.Graph()
    for word, score in keyword_scores.items():
        G.add_node(word, score=score)
    G.add_weighted_edges_from(edges)

    # ê³ ë¦½ ë…¸ë“œ ì œê±°
    G.remove_nodes_from(list(nx.isolates(G)))
    if G.number_of_nodes() == 0:
        return {"nodes": 0, "edges": 0}

    # 5. ì»¤ë®¤ë‹ˆí‹° íƒì§€
    communities = list(community.greedy_modularity_communities(G))
    for i, comm in enumerate(communities):
        for node in comm:
            G.nodes[node]['community'] = i

    # 6. PageRank ê³„ì‚°
    pagerank = nx.pagerank(G, weight='weight')

    # 7. ì»¤ë®¤ë‹ˆí‹° ëŒ€í‘œ ë¼ë²¨ ì„¤ì •
    community_labels = {}
    for i, comm in enumerate(communities):
        top_node = max(comm, key=lambda node: pagerank.get(node, 0))
        community_labels[i] = top_node

    # 8. ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(14, 10))
    pos = nx.spring_layout(G, k=2.0, iterations=50, seed=42)

    node_sizes = [100 + 2500 * G.nodes[n]['score'] for n in G.nodes()]
    community_ids = [G.nodes[n]['community'] for n in G.nodes()]
    node_colors = [plt.cm.tab20(c % 20) for c in community_ids]

    nx.draw_networkx_nodes(
        G, pos,
        node_size=node_sizes,
        node_color=node_colors,
        edgecolors='#000000',   # ë” ì§„í•œ ì™¸ê³½ì„ 
        linewidths=1.0,
        alpha=0.9,
        ax=ax
    )


    edge_weights = [d['weight'] for _, _, d in G.edges(data=True)]
    w_max = max(edge_weights, default=1)
    edge_widths = [0.3 + 2.0 * (w / w_max) for w in edge_weights]
    nx.draw_networkx_edges(G, pos, width=edge_widths, edge_color='gray', alpha=0.5, ax=ax)

    # 9. ìƒìœ„ PageRank ë…¸ë“œ ë¼ë²¨ë§
    top_nodes = sorted(pagerank, key=pagerank.get, reverse=True)[:label_top]
    texts = [
        ax.text(pos[n][0], pos[n][1], n,
                fontsize=11, ha='center', va='center',
                fontweight='bold', color="#222222")
        for n in top_nodes if n in pos
    ]

    if texts:
        adjust_text(texts, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))

    # 10. ë²”ë¡€
    legend_elements = [
        Patch(facecolor=plt.cm.tab20(i % 20), edgecolor='black', label=f'Group: {comm_label}')
        for i, comm_label in community_labels.items()
    ]
    ax.legend(
        handles=legend_elements,
        title="ì£¼ì œ ê·¸ë£¹ (Topic Groups)",
        loc='lower left',           # â† ë‚´ë¶€ë¡œ ì´ë™
        bbox_to_anchor=(0.01, 0.01),  # â† ì¢Œì¸¡ í•˜ë‹¨ ì‚´ì§ ì•ˆìª½
        frameon=True,
        framealpha=0.9,
        edgecolor='gray',
        fontsize=9,
        title_fontsize=10
    )

    ax.set_title("í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë° ì£¼ì œ ê·¸ë£¹ ë¶„ì„", fontsize=16)
    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches='tight')
    plt.close()

    print("[INFO] Saved keyword_network.png")
    return {"nodes": G.number_of_nodes(), "edges": G.number_of_edges()}

def plot_heatmap(df, topics_map):
    """ 1. ê¸°ì—…xí† í”½ ì§‘ì¤‘ë„ íˆíŠ¸ë§µ ìƒì„± """
    try:
        heatmap_data = df.pivot_table(index='org', columns='topic', values='hybrid_score', aggfunc='sum').fillna(0)
        
        # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 20ê°œ ê¸°ì—…ë§Œ ì„ íƒ
        if len(heatmap_data) > 20:
            top_orgs = heatmap_data.sum(axis=1).nlargest(20).index
            heatmap_data = heatmap_data.loc[top_orgs]

        if heatmap_data.empty: return

        plt.figure(figsize=(16, 10))
        sns.heatmap(heatmap_data, cmap="viridis", linewidths=.5)
        
        # í† í”½ IDë¥¼ í‚¤ì›Œë“œë¡œ ë³€ê²½
        plt.xticks(ticks=range(len(heatmap_data.columns)), labels=[topics_map.get(f"topic_{col}", col) for col in heatmap_data.columns], rotation=0, ha='left', fontsize=10, fontweight='bold')
        plt.title('ê¸°ì—…ë³„ í† í”½ ì§‘ì¤‘ë„ (Hybrid Score)', fontsize=16)
        plt.xlabel('í† í”½', fontsize=12)
        plt.ylabel('ê¸°ì—…', fontsize=12)
        plt.tight_layout()
        plt.savefig('outputs/fig/matrix_heatmap.png', dpi=200)
        plt.close()
        print("[INFO] Saved matrix_heatmap.png")
    except Exception as e:
        print(f"[ERROR] Failed to generate heatmap: {e}")


def plot_topic_share(df, topics_map, top_n_topics=3):
    """ 2. ìƒìœ„ í† í”½ë³„ ì ìœ ìœ¨ íŒŒì´ ì°¨íŠ¸ ìƒì„± + í‚¤ì›Œë“œ ë°•ìŠ¤ í‘œì‹œ (ìš°ì¸¡ ìƒë‹¨) """
    try:
        # ğŸ”¹ í† í”½ ì •ë³´ ë¡œë“œ
        with open("outputs/topics.json", "r", encoding="utf-8") as f:
            topics_data = json.load(f)

        top_topics = df.groupby('topic')['hybrid_score'].sum().nlargest(top_n_topics).index

        for topic in top_topics:
            topic_df = df[df['topic'] == topic].copy()

            # ğŸ”¹ ì ìœ ìœ¨ì´ ë‚®ì€ ê¸°ì—…ì€ 'Others'ë¡œ ë¬¶ê¸°
            top_orgs = topic_df.nlargest(5, 'topic_share')
            if len(topic_df) > 5:
                others_share = topic_df[~topic_df['org'].isin(top_orgs['org'])]['topic_share'].sum()
                others_row = pd.DataFrame([{'org': 'Others', 'topic_share': others_share}])
                top_orgs = pd.concat([top_orgs, others_row], ignore_index=True)

            # ğŸ”¹ í† í”½ ì´ë¦„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
            topic_obj = next((t for t in topics_data.get("topics", []) if t.get("topic_id") == topic), {})
            topic_name = topic_obj.get("topic_name", topics_map.get(f"topic_{topic}", f"Topic {topic}"))
            top_words = topic_obj.get("top_words", [])[:5]
            word_texts = [f"{w['word']} ({w['prob']:.2f})" for w in top_words if "word" in w and "prob" in w]
            box_text = "topic_word (prob)\n" + "\n".join(word_texts)  # âœ… ë°•ìŠ¤ ìƒë‹¨ ë¼ë²¨ ì¶”ê°€

            # ğŸ”¹ ì‹œê°í™”
            plt.figure(figsize=(10, 8))
            plt.pie(
                top_orgs['topic_share'],
                labels=top_orgs['org'],
                autopct='%1.1f%%',
                startangle=140,
                pctdistance=0.85
            )

            # ğŸ”¹ ì œëª© ë³€ê²½
            plt.title(f"[Topic id #{topic}, {topic_name}]", fontsize=16)

            # ğŸ”¹ í‚¤ì›Œë“œ ë°•ìŠ¤ í‘œì‹œ
            plt.gcf().text(
                0.85, 0.15, box_text,
                fontsize=10, fontweight='bold',
                bbox=dict(boxstyle="round,pad=0.4", fc="white", ec="gray", lw=0.8, alpha=0.9)
            )

            plt.axis('equal')
            plt.tight_layout()
            plt.savefig(f'outputs/fig/topic_share_{topic}.png', dpi=150)
            plt.close()
            print(f"[INFO] Saved topic_share_{topic}.png")

    except Exception as e:
        print(f"[ERROR] Failed to generate pie charts: {e}")





def plot_company_focus(df, top_n_orgs=3):
    """ 3. ìƒìœ„ ê¸°ì—…ë³„ ì§‘ì¤‘ë„ ë°” ì°¨íŠ¸ ìƒì„± (xì¶•ì— topic_id + topic_name í‘œì‹œ) """
    try:
        # topic_id â†’ topic_name ë§¤í•‘
        with open("outputs/topics.json", "r", encoding="utf-8") as f:
            topics_data = json.load(f)
        topic_label_map = {
            t["topic_id"]: f"Topic #{t['topic_id']}\n{t.get('topic_name', '')}"
            for t in topics_data.get("topics", [])
        }

        top_orgs = df.groupby('org')['hybrid_score'].sum().nlargest(top_n_orgs).index

        for org in top_orgs:
            org_df = df[df['org'] == org].nlargest(8, 'company_focus')
            if org_df.empty: continue

            # topic ë¼ë²¨ ì¹˜í™˜
            org_df["topic_label"] = org_df["topic"].map(topic_label_map).fillna(org_df["topic"].astype(str))
            
            # ì‹œê°í™”
            plt.figure(figsize=(14, 8))
            sns.barplot(data=org_df, x='topic_label', y='company_focus', palette='coolwarm')
            plt.title(f'\'{org}\'ì˜ í† í”½ë³„ ì§‘ì¤‘ë„', fontsize=16)
            plt.xlabel('í† í”½', fontsize=12)
            plt.ylabel('ì§‘ì¤‘ë„ ì ìˆ˜', fontsize=12)
            plt.xticks(rotation=45, ha='center')  # ğŸ”¹ ì¤„ë°”ê¿ˆ + ê°€ìš´ë° ì •ë ¬
            plt.tight_layout()
            plt.savefig(f'outputs/fig/company_focus_{org}.png', dpi=150)
            plt.close()
            print(f"[INFO] Saved company_focus_{org}.png")
    except Exception as e:
        print(f"[ERROR] Failed to generate bar charts: {e}")



def plot_idea_score_distribution(ideas: list, output_path: str = 'outputs/fig/idea_score_distribution.png'):
    """ ì•„ì´ë””ì–´ë³„ ì ìˆ˜ ë¶„í¬ ë°” ì°¨íŠ¸ ìƒì„± (Market, Urgency, Feasibility, Risk) """
    import matplotlib.pyplot as plt
    import os
    import numpy as np

    if not ideas:
        print("[WARN] No ideas provided for score chart.")
        return

    # ì•„ì´ë””ì–´ ì´ë¦„ì€ ìµœëŒ€ 15ìê¹Œì§€ë§Œ í‘œì‹œ
    labels = [idea.get("idea", "")[:15] + "â€¦" if len(idea.get("idea", "")) > 15 else idea.get("idea", "") for idea in ideas]
    market = [idea["score_breakdown"]["market"] for idea in ideas]
    urgency = [idea["score_breakdown"]["urgency"] for idea in ideas]
    feasibility = [idea["score_breakdown"]["feasibility"] for idea in ideas]
    risk = [idea["score_breakdown"]["risk"] for idea in ideas]

    x = np.arange(len(ideas))
    width = 0.2

    fig, ax = plt.subplots(figsize=(12, 6))
    bars1 = ax.bar(x - 1.5*width, market, width, label='Market')
    bars2 = ax.bar(x - 0.5*width, urgency, width, label='Urgency')
    bars3 = ax.bar(x + 0.5*width, feasibility, width, label='Feasibility')
    bars4 = ax.bar(x + 1.5*width, risk, width, label='Risk')

    ax.set_xticks(x)
    ax.set_xticklabels(labels, rotation=30, ha='right')
    ax.set_ylabel("Score (0.0 ~ 1.0)")
    ax.set_title("ì•„ì´ë””ì–´ë³„ ì ìˆ˜ ë¶„í¬", fontsize=16)
    ax.legend()

    # âœ… ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bars in [bars1, bars2, bars3, bars4]:
        ax.bar_label(bars, fmt="%.2f", padding=2, fontsize=9)

    fig.tight_layout()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"[INFO] Saved idea_score_distribution.png")


def plot_company_network_from_json(json_path="outputs/company_network.json",
                                   output_path="outputs/fig/company_network.png",
                                   top_edges=30, top_nodes=10):

    if not os.path.exists(json_path):
        print("[WARN] company_network.json not found")
        return

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    edges_all = data.get("edges", [])
    central = data.get("centrality", []) or []
    if not edges_all:
        print("[WARN] No edges in company_network.json")
        return

    # 1) ìƒìœ„ ì—£ì§€ ì„ ë³„
    edges_sorted = sorted(edges_all, key=lambda e: e.get("weight", 0), reverse=True)[:top_edges]

    # 2) ê·¸ë˜í”„ êµ¬ì„± (rel_type ìœ ì§€)
    G = nx.Graph()
    for e in edges_sorted:
        u, v = e.get("source"), e.get("target")
        w = float(e.get("weight", 1.0))
        r = e.get("rel_type", "neutral")
        if not u or not v:
            continue
        G.add_edge(u, v, weight=w, rel_type=r)

    if G.number_of_nodes() == 0:
        print("[WARN] Graph empty")
        return

    # 3) ê°•ì¡° ë…¸ë“œ ê¸°ì¤€: JSON ì¤‘ì‹¬ì„± ìƒìœ„ ìš°ì„ , ì—†ìœ¼ë©´ í˜„ì¬ ê·¸ë˜í”„ ê¸°ì¤€
    if central:
        top_nodes = {c.get("org") for c in central[:top_nodes] if c.get("org")}
    else:
        deg = nx.degree_centrality(G)
        top_nodes = {n for n, _ in sorted(deg.items(), key=lambda x: x[1], reverse=True)[:top_nodes]}

    # 4) í°íŠ¸ ì•ˆì „ ì„¤ì •
    try:
        # í”„ë¡œì íŠ¸ ê³µí†µ í•œê¸€ í°íŠ¸ ì„¤ì •ì„ ì¬ì‚¬ìš©
        font_name = plt.rcParams['font.family'][0]
    except Exception:
        font_name = "sans-serif"

    # 5) ë ˆì´ì•„ì›ƒ: ê°€ì¤‘ì¹˜ ë°˜ì˜(Spring)
    pos = nx.spring_layout(G, weight="weight", seed=42)

    # 6) ì—£ì§€ ìŠ¤íƒ€ì¼: rel_typeë³„ ìƒ‰ìƒ
    edge_colors = []
    weights = []
    for u, v, d in G.edges(data=True):
        weights.append(float(d.get("weight", 1.0)))
        rt = d.get("rel_type", "neutral")
        if rt == "rivalry":
            edge_colors.append("#e74c3c")   # red
        elif rt == "partnership":
            edge_colors.append("#27ae60")   # green
        else:
            edge_colors.append("#7a7a7a")   # gray

    w_arr = np.array(weights, dtype=float)
    if w_arr.size == 0:
        print("[WARN] No edge weights")
        return
    q95 = np.quantile(w_arr, 0.95)
    w_arr = np.minimum(w_arr, q95)
    w_norm = (0.6 + 1.8 * (w_arr - w_arr.min()) / (w_arr.max() - w_arr.min() + 1e-6)).tolist()

    plt.figure(figsize=(11, 8))
    nx.draw_networkx_edges(G, pos, width=w_norm, edge_color=edge_colors, alpha=0.35)

    # 7) ë…¸ë“œ ìŠ¤íƒ€ì¼
    node_colors = ["#e74c3c" if n in top_nodes else "#86b6f6" for n in G.nodes()]
    node_sizes = [1200 if n in top_nodes else 600 for n in G.nodes()]
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors,
                           edgecolors="#333", linewidths=0.6, alpha=0.95)
    nx.draw_networkx_labels(G, pos, font_size=9, font_color="#222", font_family=font_name)

    # 8) ë²”ë¡€(ê°„ë‹¨ í‘œê¸°)
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], color="#e74c3c", lw=2, label="ê²½ìŸ"),
        Line2D([0], [0], color="#27ae60", lw=2, label="í˜‘ë ¥"),
        Line2D([0], [0], color="#7a7a7a", lw=2, label="ì¤‘ë¦½"),
        Line2D([0], [0], marker='o', color='w', label='í—ˆë¸Œ(ê°•ì¡°)',
               markerfacecolor="#e74c3c", markeredgecolor="#333", markersize=10)
    ]

    # ë²”ë¡€ ì¶”ê°€ (ê·¸ë˜í”„ ë‚´ë¶€ ë¹ˆ ê³µê°„ì— ìœ„ì¹˜, í…Œë‘ë¦¬ í¬í•¨)
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], color="#e74c3c", lw=2, label="ê²½ìŸ"),       # ë¹¨ê°„ ì„ 
        Line2D([0], [0], color="#27ae60", lw=2, label="í˜‘ë ¥"),       # ì´ˆë¡ ì„ 
        Line2D([0], [0], color="#7a7a7a", lw=2, label="ì¤‘ë¦½"),       # íšŒìƒ‰ ì„ 
        Line2D([0], [0], marker='o', color='w', label='í—ˆë¸Œ ê¸°ì—…',   # ë¹¨ê°„ ë…¸ë“œ
               markerfacecolor="#e74c3c", markeredgecolor="#333", markersize=10),
        Line2D([0], [0], marker='o', color='w', label='ì¼ë°˜ ê¸°ì—…',    # íŒŒë€ ë…¸ë“œ
               markerfacecolor="#86b6f6", markeredgecolor="#333", markersize=8)
    ]

    # ë²”ë¡€ ì¶”ê°€ (ê·¸ë˜í”„ ì•ˆìª½ ì¢Œí•˜ë‹¨ + í…Œë‘ë¦¬ ì¶”ê°€)
    legend = plt.legend(handles=legend_elements,
                        loc="lower left",
                        frameon=True,
                        framealpha=1,
                        edgecolor="#333",
                        fontsize=9)
    legend.get_frame().set_linewidth(0.8)

    # ê·¸ë˜í”„ ì „ì²´ í…Œë‘ë¦¬ ì¶”ê°€
    ax = plt.gca()
    ax.add_patch(plt.Rectangle(
        (0, 0), 1, 1, transform=ax.transAxes,
        fill=False, edgecolor="#555", linewidth=1.2
    ))


    plt.title("ê¸°ì—… ê²½ìŸ/í˜‘ë ¥ ë„¤íŠ¸ì›Œí¬ (í•µì‹¬ ê´€ê³„ë§)", fontsize=14, fontname=font_name)
    plt.axis("off")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.tight_layout()
    plt.savefig(output_path, dpi=150)
    plt.close()
    print(f"[INFO] Saved simplified company_network.png with {len(G.nodes())} nodes and {len(G.edges())} edges")


def plot_tech_maturity_map(maturity_data):
    """ 4. ê¸°ìˆ  ì„±ìˆ™ë„ ë§µ ë²„ë¸” ì°¨íŠ¸ ìƒì„± (ë²”ë¡€ë¥¼ ì°¨íŠ¸ ì•ˆì— í‘œì‹œ) """
    if not maturity_data.get("results"):
        return

    records = []
    for item in maturity_data["results"]:
        tech = item.get("technology")
        metrics = item.get("metrics", {})
        analysis = item.get("analysis", {})
        records.append({
            "technology": tech,
            "frequency": metrics.get("frequency", 0),
            "sentiment": metrics.get("sentiment", 0.0),
            "events": sum(metrics.get("events", {}).values()),
            "stage": analysis.get("stage", "N-A")
        })

    df = pd.DataFrame(records)
    if df.empty:
        return

    # âœ… ì„±ìˆ™ë„ ë‹¨ê³„ë³„ ìƒ‰ìƒ ì§€ì •
    stage_palette = {
        "Emerging": "#9CA3AF",   # íšŒìƒ‰
        "Growth": "#10B981",     # ë…¹ìƒ‰
        "Maturity": "#3B82F6",   # íŒŒë€ìƒ‰
        "N-A": "#D1D5DB"         # ë°ì´í„° ì—†ìŒ â†’ ì—°íšŒìƒ‰
    }

    plt.figure(figsize=(12, 8))
    ax = plt.gca()

    sns.scatterplot(
        data=df, x="frequency", y="sentiment", size="events",
        hue="stage", sizes=(200, 2000), alpha=0.7,
        palette=stage_palette, ax=ax  # âœ… ê³ ì •ëœ ìƒ‰ìƒ ì‚¬ìš©
    )

    # ê¸°ìˆ  ë¼ë²¨ í‘œì‹œ
    texts = []
    for i in range(df.shape[0]):
        texts.append(ax.text(
            x=df.frequency[i], y=df.sentiment[i], s=df.technology[i],
            fontdict=dict(color='black', size=11, weight='bold')  # âœ… ê¸€ì ì§„í•˜ê²Œ
        ))

    adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray', lw=0.5))

    plt.title('ê¸°ìˆ  ì„±ìˆ™ë„ ë§µ (Technology Maturity Map)', fontsize=16)
    plt.xlabel('ì‹œì¥ ê´€ì‹¬ë„ (ë‰´ìŠ¤ ë¹ˆë„)', fontsize=12)
    plt.ylabel('ì‹œì¥ ê¸ì •ì„± (ê°ì„± ì ìˆ˜)', fontsize=12)

    # ë²”ë¡€ ì„¤ì •
    handles, labels = ax.get_legend_handles_labels()
    num_stages = df['stage'].nunique()
    stage_handles = handles[1:num_stages+1]
    stage_labels = labels[1:num_stages+1]

    legend = ax.legend(stage_handles, stage_labels, title='ì„±ìˆ™ë„ ë‹¨ê³„', loc='best', frameon=True, framealpha=0.8)
    if legend:
        legend.get_title().set_fontsize('14')
        for text in legend.get_texts():
            text.set_fontsize('12')

    plt.grid(True)
    plt.tight_layout()
    plt.savefig('outputs/fig/tech_maturity_map.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("[INFO] Saved tech_maturity_map.png")


def plot_weak_signal_radar(weak_signals_df):
    """ 5. ì•½í•œ ì‹ í˜¸ ë ˆì´ë” ì°¨íŠ¸ ìƒì„± (ë¼ë²¨ ìˆ˜ì • ë²„ì „) """
    if weak_signals_df.empty:
        return

    plt.figure(figsize=(12, 8))
    ax = plt.gca() # ì¶• ê°ì²´ ê°€ì ¸ì˜¤ê¸°
    sns.scatterplot(
        data=weak_signals_df, x="total", y="z_like", size="cur",
        sizes=(100, 1000), alpha=0.7, color="red", ax=ax, legend=False
    )

    # --- âœ¨ ì‹œì¸ì„± í–¥ìƒëœ ë¼ë²¨ ì¶”ê°€ âœ¨ ---
    texts = []
    for i in range(weak_signals_df.shape[0]):
        label = weak_signals_df.term[i]
        x = weak_signals_df.total[i]
        y = weak_signals_df.z_like[i]
        texts.append(ax.text(
            x, y, label,
            fontsize=11,
            color='black',  # ë¼ë²¨ ìƒ‰: ëŒ€ë¹„ë¥¼ ìœ„í•´ ê²€ì •
            bbox=dict(boxstyle="round,pad=0.2", fc="white", ec="gray", lw=0.5, alpha=0.8)  # í° ë°°ê²½ ë°•ìŠ¤
        ))

    adjust_text(
        texts, ax=ax,
        arrowprops=dict(arrowstyle='->', color='gray', lw=0.5)  # í™”ì‚´í‘œëŠ” íë¦° íšŒìƒ‰
    )


    plt.title('ì•½í•œ ì‹ í˜¸ ë ˆì´ë” (Weak Signal Radar)', fontsize=16)
    plt.xlabel('ìµìˆ™í•¨ (ì´ ëˆ„ì  ì–¸ê¸‰ëŸ‰)', fontsize=12)
    plt.ylabel('ì„íŒ©íŠ¸ (í†µê³„ì  ê¸‰ë“± ìˆ˜ì¤€)', fontsize=12)

    if not weak_signals_df.empty:
        plt.axhline(0.8, color='gray', linestyle='--', linewidth=0.8)
        plt.text(weak_signals_df['total'].max(), 0.8, '  ì£¼ëª© ê¸°ì¤€ì„ ', color='gray', va='bottom')

    plt.grid(True)
    plt.tight_layout()
    plt.savefig('outputs/fig/weak_signal_radar.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("[INFO] Saved weak_signal_radar.png")

def plot_strong_signals(strong_signals_df):
    """ 6. ê°•í•œ ì‹ í˜¸ ì„íŒ©íŠ¸ ìˆœìœ„ ë°” ì°¨íŠ¸ ìƒì„± (ì¢Œìš° ëŒ€ì¹­ ë° ê°’ í‘œì‹œ ë²„ì „) """
    if strong_signals_df.empty:
        return

    rising = strong_signals_df[strong_signals_df['z_like'] > 0].head(5)
    rising['trend'] = 'ìƒìŠ¹(Rising)'

    falling = strong_signals_df[strong_signals_df['z_like'] < 0].tail(5)
    falling['trend'] = 'í•˜ê°•(Falling)'

    combined = pd.concat([rising, falling]).sort_values('z_like', ascending=False)
    
    if combined.empty:
        print("[INFO] No significant rising or falling signals to plot.")
        return

    plt.figure(figsize=(12, 8))
    ax = plt.gca()
    
    sns.barplot(
        data=combined,
        y="term",
        x="z_like",
        hue="trend",
        palette={"ìƒìŠ¹(Rising)": "#3b82f6", "í•˜ê°•(Falling)": "#ef4444"},
        dodge=False,
        ax=ax
    )

    # --- âœ¨âœ¨âœ¨ 1. ì¢Œìš° ëŒ€ì¹­ì„ ìœ„í•œ Xì¶• ë²”ìœ„ ì„¤ì • âœ¨âœ¨âœ¨ ---
    # z_like ê°’ì˜ ì ˆëŒ€ê°’ ì¤‘ ê°€ì¥ í° ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì¢Œìš° ëŒ€ì¹­ ì„¤ì •
    max_abs_z = combined['z_like'].abs().max()
    limit = max_abs_z * 1.2  # ì•½ê°„ì˜ ì—¬ë°± ì¶”ê°€
    ax.set_xlim(-limit, limit)
    # --- âœ¨âœ¨âœ¨ ì—¬ê¸°ê¹Œì§€ ---

    # --- âœ¨âœ¨âœ¨ 2. ê° ë§‰ëŒ€ì— ê°’(z_like ì ìˆ˜) í‘œì‹œ âœ¨âœ¨âœ¨ ---
    for p in ax.patches:
        width = p.get_width()
        # ê°’ì˜ ìœ„ì¹˜ë¥¼ ë§‰ëŒ€ ëì—ì„œ ì•½ê°„ ë–¨ì–´ì§€ê²Œ ì„¤ì •
        x_pos = width + (limit * 0.02) if width > 0 else width - (limit * 0.02)
        
        # í…ìŠ¤íŠ¸ ì •ë ¬ ì„¤ì •
        ha = 'left' if width > 0 else 'right'
        
        ax.text(x=x_pos, 
                y=p.get_y() + p.get_height() / 2, 
                s=f'{width:.2f}', # ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€ í‘œì‹œ
                va='center', 
                ha=ha,
                fontsize=10)
    # --- âœ¨âœ¨âœ¨ ì—¬ê¸°ê¹Œì§€ ---

    plt.title('ì£¼ìš” ì‹ í˜¸ ì‹œê³„ì—´ ë³€í™” (ìƒìŠ¹/í•˜ê°•)', fontsize=16)
    plt.xlabel('ì„íŒ©íŠ¸ (z_like)', fontsize=12)
    plt.ylabel('í‚¤ì›Œë“œ', fontsize=12)
    ax.axvline(0, color='grey', linewidth=0.8)
    plt.grid(axis='x', linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.savefig('outputs/fig/strong_signals_barchart.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("[INFO] Saved strong_signals_barchart.png")



def main():
    """ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ """
    # í°íŠ¸ ì„¤ì •
    ensure_fonts()

    keywords, topics, ts, insights, opps, meta_items = load_data()
    os.makedirs("outputs/fig", exist_ok=True)
    try:
        plot_top_keywords(keywords)
    except Exception as e:
        print("[WARN] top_keywords ê·¸ë¦¼ ì‹¤íŒ¨:", e)
    try:
        plot_topics(topics)
    except Exception as e:
        print("[WARN] topics ê·¸ë¦¼ ì‹¤íŒ¨:", e)
    try:
        plot_wordcloud_from_keywords(keywords)
    except Exception as e:
        print("[WARN] wordcloud ìƒì„± ì‹¤íŒ¨:", e)
    try:
        plot_timeseries(ts)
    except Exception as e:
        print("[WARN] timeseries ê·¸ë¦¼ ì‹¤íŒ¨:", e)
    try:
        docs = build_docs_from_meta(meta_items)
        kw_list = keywords.get("keywords", [])
        n_kw = len(kw_list)
        label_cap = 25
        plot_keyword_network(
            keywords, docs,
            out_path="outputs/fig/keyword_network.png",
            topn=n_kw,
            min_cooccur=1,
            max_edges=200,
            label_top=(None if n_kw <= label_cap else label_cap)
        )
    except Exception as e:
        print("[WARN] í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨:", e)

    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv('outputs/export/company_topic_matrix_long.csv')
    except FileNotFoundError:
        print("[ERROR] company_topic_matrix_long.csv not found. Please run module_d.py first.")
        return

    # í† í”½ í‚¤ì›Œë“œ ë§µ ë¡œë“œ
    try:
        with open('outputs/topics.json', 'r', encoding='utf-8') as f:
            topics_data = json.load(f)
        topics_map = {f"topic_{t['topic_id']}": ", ".join(w['word'] for w in t['top_words'][:2]) for t in topics_data['topics']}
    except Exception:
        topics_map = {}
        print("[WARN] topics.json not found or failed to parse. Topic IDs will be used as labels.")

    #plot_idea_score_distribution
    try:
        with open('outputs/biz_opportunities.json', 'r', encoding='utf-8') as f:
            ideas_data = json.load(f)
        top_ideas = sorted(ideas_data["ideas"], key=lambda it: it.get("score", 0), reverse=True)[:5]
        plot_idea_score_distribution(top_ideas)
    except Exception as e:
        import traceback
        print(f"[ERROR] Failed to generate idea score chart: {e}")
        traceback.print_exc()
    
    # ê¸°ì—… ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
    try:
        plot_company_network_from_json("outputs/company_network.json", "outputs/fig/company_network.png")
    except Exception as e:
        print(f"[WARN] company network visualization failed: {repr(e)}")

    # ê¸°ìˆ  ì„±ìˆ™ë„ ë ˆì´ë” ì‹œê°í™”
    try:
        tech_maturity_data = load_json('outputs/tech_maturity.json')
    except Exception:
        tech_maturity_data = {"results": []}
        print("[WARN] tech_maturity.json not found.")

    try:
        strong_signals_df = pd.read_csv('outputs/export/trend_strength.csv')
    except FileNotFoundError:
        strong_signals_df = pd.DataFrame()
        print("[WARN] trend_strength.csv not found.")

    try:
        weak_signals_df = pd.read_csv('outputs/export/weak_signals.csv')
    except FileNotFoundError:
        weak_signals_df = pd.DataFrame()
        print("[WARN] weak_signals.csv not found.")


    # ì‹œê°í™” í•¨ìˆ˜ í˜¸ì¶œ
    os.makedirs('outputs/fig', exist_ok=True)
    plot_heatmap(df, topics_map)
    plot_topic_share(df, topics_map)
    plot_company_focus(df)
    plot_tech_maturity_map(tech_maturity_data)
    plot_weak_signal_radar(weak_signals_df)
    plot_strong_signals(strong_signals_df)

    # ì¶”ê°€ ì´ë¯¸ì§€
    gen_timeseries_spikes()
    gen_strong_signals_bar()
    gen_topics_bubble()
    
    print("\n[SUCCESS] All visualizations have been generated in 'outputs/fig/'")

if __name__ == '__main__':
    main()