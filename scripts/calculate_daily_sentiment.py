import pandas as pd
from src.utils import load_json, latest
import os
import re
from transformers import pipeline
from datetime import datetime, timedelta

# --- ëª¨ë¸ ë¡œë“œ ---
# Hugging Face Hub ëª¨ë¸ ì´ë¦„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
HF_MODEL_NAME = "beomi/KcELECTRA-base-v2022"
OUTPUT_CSV = "outputs/export/daily_topic_sentiment.csv"

def get_sentiment_analyzer():
    """Hugging Face Hubì—ì„œ ê°ì„± ë¶„ì„ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    # âœ… Hugging Face Hubì—ì„œ ë°”ë¡œ ëª¨ë¸ ë¡œë“œ (ë¡œì»¬/ê¹ƒì•¡ì…˜ ë™ì¼)
    from transformers import pipeline
    try:
        sentiment_analyzer = pipeline("sentiment-analysis", model=HF_MODEL_NAME, tokenizer=HF_MODEL_NAME, device=-1) # CPU ì‚¬ìš©
        print(f"[INFO] ê°ì„± ë¶„ì„ ëª¨ë¸ì„ Hugging Face Hubì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {HF_MODEL_NAME}")
        return sentiment_analyzer
    except Exception as e:
        print(f"[WARN] ê°ì„± ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}. ê°ì„± ì ìˆ˜ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
        return None
# --- ğŸ’¡ ìˆ˜ì • ì™„ë£Œ ---

def calculate_sentiments():
    """
    ìµœì‹  ê¸°ì‚¬ ë°ì´í„°ì™€ í† í”½ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í† í”½ë³„ ì¼ì¼ ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ëˆ„ì  ì €ì¥í•©ë‹ˆë‹¤.
    """
    analyzer = get_sentiment_analyzer()
    if not analyzer:
        return

    # 1. ë°ì´í„° ë¡œë“œ
    meta_items = load_json(latest("data/news_meta_*.json"), [])
    topics_data = load_json("outputs/topics.json", {"topics": []})
    
    if not meta_items or not topics_data.get("topics"):
        print("[INFO] No data to process for sentiment calculation.")
        return

    today_date = pd.to_datetime("today").strftime("%Y-%m-%d")

    # 2. í† í”½ë³„ë¡œ ê¸°ì‚¬ ë§¤í•‘ ë° ê°ì„± ë¶„ì„
    topic_sentiments = {} # {topic_id: [score1, score2, ...]}
    for topic in topics_data["topics"]:
        topic_id = topic["topic_id"]
        topic_keywords = [w["word"] for w in topic.get("top_words", [])]
        topic_sentiments[topic_id] = []

        keyword_pattern = re.compile('|'.join(re.escape(kw) for kw in topic_keywords), re.IGNORECASE)

        for item in meta_items:
            content = item.get("body") or item.get("description", "")
            if content and keyword_pattern.search(content):
                try:
                    result = analyzer(content, truncation=True, max_length=512)[0]
                    # KcELECTRA ëª¨ë¸ì€ 'LABEL_0'(ë¶€ì •), 'LABEL_1'(ê¸ì •)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
                    # 'LABEL_1'ì¼ ê²½ìš° score, 'LABEL_0'ì¼ ê²½ìš° 1 - scoreë¡œ ë³€í™˜í•˜ì—¬ ê¸ì • ì ìˆ˜ë¡œ í†µì¼í•©ë‹ˆë‹¤.
                    score = result['score'] if result['label'] == 'LABEL_1' else 1 - result['score']
                    topic_sentiments[topic_id].append(score)
                except Exception:
                    continue
    
    # 3. í† í”½ë³„ í‰ê·  ê°ì„± ì ìˆ˜ ê³„ì‚°
    results = []
    for topic_id, scores in topic_sentiments.items():
        if scores:
            avg_score = sum(scores) / len(scores)
            results.append({
                "date": today_date,
                "topic_id": topic_id,
                "avg_sentiment": round(avg_score, 4),
                "article_count": len(scores)
            })

    # 4. CSV íŒŒì¼ì— ëˆ„ì  ì €ì¥ (ìµœì‹  90ì¼ ë°ì´í„°ë§Œ ìœ ì§€)
    df_new = pd.DataFrame(results)
    if os.path.exists(OUTPUT_CSV):
        df_existing = pd.read_csv(OUTPUT_CSV)
        df_existing = df_existing[df_existing["date"] != today_date]
        df_final = pd.concat([df_existing, df_new], ignore_index=True)
    else:
        df_final = df_new
    
    # 90ì¼ ì´ì „ ë°ì´í„° ì‚­ì œ ë¡œì§
    df_final['date'] = pd.to_datetime(df_final['date'])
    ninety_days_ago = datetime.now() - timedelta(days=90)
    df_final = df_final[df_final['date'] >= ninety_days_ago]
    df_final['date'] = df_final['date'].dt.strftime('%Y-%m-%d')
    
    df_final.sort_values(by=["date", "topic_id"], inplace=True)

    # CSV ì €ì¥ ì „ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)

    df_final.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")
    print(f"[INFO] Daily topic sentiments calculated and saved to {OUTPUT_CSV}. ({len(df_new)} topics processed)")

if __name__ == "__main__":
    calculate_sentiments()
