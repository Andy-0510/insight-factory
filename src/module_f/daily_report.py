# íŒŒì¼ ê²½ë¡œ: src/module_f/daily_report.py

import os
import re
import glob
import json
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
from src.utils import load_json, save_json, latest

# --- ì„¤ì • ---
ROOT_OUTPUT_DIR = "outputs"
FIG_DIR = os.path.join(ROOT_OUTPUT_DIR, "fig")
EXPORT_DIR = os.path.join(ROOT_OUTPUT_DIR, "export")
OUT_MD = os.path.join(ROOT_OUTPUT_DIR, "report.md")
OUT_HTML = os.path.join(ROOT_OUTPUT_DIR, "report.html")

# --- í—¬í¼ í•¨ìˆ˜ ---
def _fmt_int(x):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    try: return f"{int(x):,}"
    except Exception:
        try: return f"{float(x):.0f}"
        except Exception: return str(x) if x is not None else "-"
def _fmt_float(x, nd=2):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    try: return f"{float(x):.{nd}f}"
    except Exception: return "-"
def _truncate(s, n=80):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    s = (s or "").strip().replace("\n", " "); return s if len(s) <= n else s[:n-1] + "â€¦"
def _exists(path):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    return path and os.path.exists(path)
def _safe_read_csv(path, **kwargs):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    try:
        if _exists(path): return pd.read_csv(path, **kwargs)
    except Exception: pass
    return pd.DataFrame()
def _to_markdown_table(df: pd.DataFrame, max_rows=50):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    if df is None or df.empty: return "- (ë°ì´í„° ì—†ìŒ)\n"
    return df.head(max_rows).copy().to_markdown(index=False) + "\n"
def _load_data():
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    return {
        "keywords": load_json("outputs/keywords.json", {"keywords": [], "stats": {}}),
        "topics": load_json("outputs/topics.json", {"topics": []}),
        "ts": load_json("outputs/trend_timeseries.json", {"daily": []}),
        "insights": load_json("outputs/trend_insights.json", {"summary": "", "top_topics": [], "evidence": {}}),
        "opps": load_json("outputs/biz_opportunities.json", {"ideas": []}),
        "tech_maturity": load_json("outputs/tech_maturity.json", {"results": []}),
        "weak_insights": load_json("outputs/weak_signal_insights.json", {"results": []}),
        "meta_items": load_json(latest("data/news_meta_*.json"), [])
    }
def _section_header(title):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    return f"\n## {title}\n"

# --- â–¼â–¼â–¼â–¼â–¼â–¼ [ìˆ˜ì •] _insert_images í•¨ìˆ˜ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤ â–¼â–¼â–¼â–¼â–¼â–¼ ---
def _insert_images(image_paths, md_out_path, captions=None):
    lines = []
    if not isinstance(image_paths, (list, tuple)): image_paths = [image_paths]
    captions = captions or []
    md_dir = os.path.dirname(md_out_path)
    for i, p in enumerate(image_paths):
        if _exists(p):
            relative_path = os.path.relpath(p, start=md_dir).replace("\\", "/")
            cap = captions[i] if i < len(captions) else ""
            lines.append(f"![{cap or 'Figure'}]({relative_path})")
    return ("\n".join(lines) + "\n") if lines else ""
# --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---

def _section_time_series(data):
    """ì¼ì¼ ì‹œì¥ í™œë™ëŸ‰ ë° ì´ìƒ ì§•í›„ (ìµœê·¼ 30ì¼ ê¸°ì¤€)"""
    ts = data.get("ts", {})
    daily = ts.get("daily", [])
    df_ts_full = pd.DataFrame(daily)
    
    # --- â–¼â–¼â–¼ [ì¶”ê°€] ì‹ í˜¸ ê¸°ì‚¬ ë¹„ìœ¨ ê³„ì‚° â–¼â–¼â–¼ ---
    df_signal = _safe_read_csv(os.path.join(EXPORT_DIR, "daily_signal_counts.csv"))
    if not df_ts_full.empty and not df_signal.empty:
        df_merged = pd.merge(df_ts_full, df_signal, on="date", how="left").fillna(0)
        df_merged['signal_ratio'] = (df_merged['signal_article_count'] / df_merged['count']).where(df_merged['count'] > 0, 0)
        avg_ratio_30days = df_merged.tail(30)['signal_ratio'].mean()
    else:
        avg_ratio_30days = 0
    # --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---

    df_ts_30days = df_ts_full.tail(30)
    if df_ts_30days.empty: return "- (ì‹œê³„ì—´ ë°ì´í„° ë¶€ì¡±)\n"
    
    date_range = f"{df_ts_30days.iloc[0]['date']} ~ {df_ts_30days.iloc[-1]['date']}"
    
    lines = [
        f"- **ë¶„ì„ ê¸°ê°„:** {date_range} (ìµœê·¼ 30ì¼)",
        f"- **ìµœê·¼ 30ì¼ í‰ê·  ì‹ í˜¸ ê¸°ì‚¬ ë¹„ìœ¨:** {avg_ratio_30days:.2%}" # <-- ë¹„ìœ¨ í…ìŠ¤íŠ¸ ì¶”ê°€
    ]
    
    # ì´ë¯¸ì§€ëŠ” ì´ì œ ê°•í™”ëœ ë²„ì „ìœ¼ë¡œ ìë™ êµì²´ë¨
    lines.append(_insert_images(os.path.join(FIG_DIR, "timeseries.png"), OUT_MD, captions=["ì¼ì¼ ê¸°ì‚¬ëŸ‰, ì‹ í˜¸ ê¸°ì‚¬ ë¹„ìœ¨ ë° ìŠ¤íŒŒì´í¬ ì¶”ì´"]))
    
    # --- â–¼â–¼â–¼â–¼â–¼ [ìˆ˜ì •] ìŠ¤íŒŒì´í¬ í…Œì´ë¸”ì„ ë‘ ê°œë¡œ ë¶„ë¦¬í•˜ì—¬ í‘œì‹œ â–¼â–¼â–¼â–¼â–¼ ---
    df_spikes = _safe_read_csv(os.path.join(EXPORT_DIR, "timeseries_spikes_enhanced.csv"))
    if not df_spikes.empty:
        start_date_30days = pd.to_datetime(df_ts_30days.iloc[0]['date'])
        df_spikes['date'] = pd.to_datetime(df_spikes['date'])
        df_spikes_recent = df_spikes[df_spikes['date'] >= start_date_30days].copy()
        
        if not df_spikes_recent.empty:
            df_spikes_recent['date'] = df_spikes_recent['date'].dt.strftime('%Y-%m-%d')
            
            # 1. ì „ì²´ ê¸°ì‚¬ëŸ‰ ìŠ¤íŒŒì´í¬ í…Œì´ë¸”
            df_count_spikes = df_spikes_recent[df_spikes_recent['metric'] == 'ì „ì²´ ê¸°ì‚¬ëŸ‰'].copy()
            if not df_count_spikes.empty:
                lines.append("### ğŸ“ˆ ì „ì²´ ê¸°ì‚¬ëŸ‰ ìŠ¤íŒŒì´í¬")
                lines.append(_to_markdown_table(df_count_spikes[['date', 'value', 'z_score']].rename(columns={
                    'date': 'ë‚ ì§œ', 'value': 'ê¸°ì‚¬ëŸ‰', 'z_score': 'Z-Score'
                })))

            # 2. ì‹ í˜¸ ê¸°ì‚¬ ë¹„ìœ¨ ìŠ¤íŒŒì´í¬ í…Œì´ë¸”
            df_ratio_spikes = df_spikes_recent[df_spikes_recent['metric'] == 'ì‹ í˜¸ ê¸°ì‚¬ ë¹„ìœ¨'].copy()
            if not df_ratio_spikes.empty:
                lines.append("### ì‹ í˜¸ ê¸°ì‚¬ ë¹„ìœ¨ ìŠ¤íŒŒì´í¬")
                lines.append(_to_markdown_table(df_ratio_spikes[['date', 'value', 'z_score']].rename(columns={
                    'date': 'ë‚ ì§œ', 'value': 'ë¹„ìœ¨', 'z_score': 'Z-Score'
                })))
    # --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---
        
    return "\n".join(lines)

def _section_signals_board(data):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    df_strong = _safe_read_csv(os.path.join(EXPORT_DIR, "trend_strength.csv"))
    if not df_strong.empty:
        rows = [{"ëª¨ë©˜í…€ í† í”½": row.get("term"), "z_like ì ìˆ˜": _fmt_float(row.get("z_like"), 2), "ê¸ˆì¼ ì–¸ê¸‰ëŸ‰": _fmt_int(row.get("cur"))} for _, row in df_strong.head(3).iterrows()]
        return _to_markdown_table(pd.DataFrame(rows))
    return "- (ê°•í•œ ì‹ í˜¸ ë°ì´í„° ì—†ìŒ)\n"

def _section_competitor_events(data):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    df_events = _safe_read_csv(os.path.join(EXPORT_DIR, "events.csv"))
    if not df_events.empty:
        rows = [{"ë‚ ì§œ": row.get("date", ""), "ìœ í˜•": row.get("types", ""), "ì œëª©": _truncate(row.get("title", ""), 100)} for _, row in df_events.head(5).iterrows()]
        return _to_markdown_table(pd.DataFrame(rows))
    return "- (ì£¼ìš” ì´ë²¤íŠ¸ ë°ì´í„° ì—†ìŒ)\n"

def _section_top_articles(data):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    df_articles = _safe_read_csv(os.path.join(EXPORT_DIR, "today_article_list.csv"))
    if not df_articles.empty:
        df_articles['ì œëª©'] = df_articles.apply(lambda row: f"[{_truncate(row['title'], 100)}]({row['url']})", axis=1)
        return _to_markdown_table(df_articles[['ì œëª©']])
    return "- (ì„ ì •ëœ ì£¼ìš” ê¸°ì‚¬ ì—†ìŒ)\n"

def build_html_from_md_new(md_path=OUT_MD, out_html=OUT_HTML):
    # ... (ê¸°ì¡´ê³¼ ë™ì¼)
    try:
        import markdown
        with open(md_path, "r", encoding="utf-8") as f: md = f.read()
        html = markdown.markdown(md, extensions=["extra", "tables", "toc"])
        html_tpl = f"""<!doctype html><html lang="ko"><head><meta charset="utf-8"><title>Daily Briefing</title><style>body{{font-family:sans-serif;line-height:1.6;padding:24px;max-width:900px;margin:20px auto}}img{{max-width:100%;border:1px solid #ddd}}table{{border-collapse:collapse;width:100%}}th,td{{border:1px solid #ddd;padding:8px}}th{{background:#f7f7f7}}h2{{margin-top:32px;border-bottom:2px solid #eee}}</style></head><body>{html}</body></html>"""
        with open(out_html, "w", encoding="utf-8") as f: f.write(html_tpl)
    except Exception as e: print(f"[WARN] HTML ë³€í™˜ ì‹¤íŒ¨: {e}")

# --- main í•¨ìˆ˜ ---
def build_daily_markdown():
    data = _load_data(); today_str = datetime.now().strftime("%Y-%m-%d")
    lines = [f"# Daily Briefing ({today_str})"]
    lines.append(_section_header("1. ì‹œì¥ í™œë™ëŸ‰ ë° ì´ìƒ ì§•í›„")); lines.append(_section_time_series(data))
    lines.append(_section_header("2. í•µì‹¬ ëª¨ë©˜í…€ í† í”½ Top 3")); lines.append(_section_signals_board(data))
    lines.append(_section_header("3. ê²½ìŸì‚¬ ì£¼ìš” í™œë™")); lines.append(_section_competitor_events(data))
    lines.append(_section_header("4. ì£¼ìš” ê¸°ì‚¬")); lines.append(_section_top_articles(data))
    with open(OUT_MD, "w", encoding="utf-8") as f: f.write("\n".join(lines))
    return OUT_MD

def main():
    try:
        md_path = build_daily_markdown()
        build_html_from_md_new(md_path, OUT_HTML)
        print(f"[INFO] Daily report generated: {md_path}, {OUT_HTML}")
    except Exception as e: print(f"[ERROR] Daily report generation failed: {e}")

if __name__ == "__main__":
    main()
