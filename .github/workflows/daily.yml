name: Daily Pipeline

permissions:
  contents: write

on:
  schedule:
    - cron: "0 21 * * *" # UTC 21:00 = KST 06:00
  workflow_dispatch:
    inputs:
      dry_run:
        description: "ë“œë¼ì´ ëŸ°"
        required: true
        default: "true"
      pro_mode:
        description: "Pro ëª¨ë“œë¡œ ì‹¤í–‰í• ê¹Œìš”? (true/false)"
        required: false
        default: "false"

concurrency:
  group: daily-${{ github.ref_name }}
  cancel-in-progress: false

jobs:
  pipeline:
    runs-on: ubuntu-latest
    env:
      USE_PRO: ${{ github.event_name == 'workflow_dispatch' && inputs.pro_mode || 'false' }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      HF_HOME: ~/.cache/huggingface

    steps:
      # 1ï¸âƒ£ Checkout (LFS ì œê±°)
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: false   # ğŸ”¹ LFS ì™„ì „ ë¹„í™œì„±í™”

      # 2ï¸âƒ£ Python í™˜ê²½ ì„¸íŒ…
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: "requirements.txt"

      # 3ï¸âƒ£ Hugging Face ëª¨ë¸ ìºì‹œ ì¶”ê°€
      - name: Cache HuggingFace models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-hfmodels
          restore-keys: |
            ${{ runner.os }}-hfmodels

      # 4ï¸âƒ£ ì˜ì¡´ì„± ì„¤ì¹˜
      - name: Install dependencies
        shell: bash
        run: |
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      # 5ï¸âƒ£ ì‹œê°í™” í°íŠ¸ ì„¤ì¹˜
      - name: Install viz deps
        shell: bash
        run: |
          source .venv/bin/activate
          sudo apt-get update
          sudo apt-get install -y fonts-nanum fonts-noto-cjk
          fc-cache -f -v

      # 6ï¸âƒ£ í”„ë¦¬í”Œë¼ì´íŠ¸: í™˜ê²½ ë³€ìˆ˜ í™•ì¸
      - name: Preflight | Check secrets
        shell: bash
        run: |
          test -n "${{ secrets.GEMINI_API_KEY }}" || (echo "GEMINI_API_KEY ì—†ìŒ"; exit 1)
          if [ -z "${{ secrets.NAVER_CLIENT_ID }}" ] || [ -z "${{ secrets.NAVER_CLIENT_SECRET }}" ]; then
            echo "[WARN] NAVER API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤(ì˜µì…˜?)."
          fi

      # --- ì´í•˜ ëª¨ë“ˆ ì‹¤í–‰ ë¶€ë¶„ì€ ë™ì¼ ---
      - name: Module A - Fetch & Preprocess
        shell: bash
        env:
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
          DRY_RUN: ${{ github.event_name == 'workflow_dispatch' && inputs.dry_run || 'false' }}
        run: |
          source .venv/bin/activate
          python -m src.module_a

      - name: Check A - Validate Output
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.check_a

      - name: Warehouse Append
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.warehouse_append

      - name: Commit & Push Warehouse
        shell: bash
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/warehouse
          git commit -m "chore: warehouse append $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "no changes"
          git pull --rebase --autostash origin ${{ github.ref_name }} || true
          git push origin HEAD:${{ github.ref_name }} || true

      - name: Enrich meta with article bodies
        shell: bash
        env:
          BODY_MIN_LEN: "200"
        run: |
          source .venv/bin/activate
          python -m scripts.fetch_article_bodies

      - name: Copy latest meta file for debugging
        shell: bash
        run: |
          set -e
          mkdir -p outputs/debug
          LATEST_META=$(ls -t data/news_meta_*.json | head -n 1)
          if [ -f "$LATEST_META" ]; then
            echo "Copying $LATEST_META to outputs/debug/news_meta_latest.json"
            cp "$LATEST_META" outputs/debug/news_meta_latest.json
          else
            echo "WARN: No news_meta_*.json file found to copy."
          fi

      - name: Module B - Keywords
        shell: bash
        run: |
          source .venv/bin/activate
          echo "[INFO] USE_PRO=${USE_PRO} â†’ Module B ì‹¤í–‰(ì›Œí¬í”Œë¡œìš°)"
          python -m src.module_b

      - name: Check B - Validate Keywords
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.check_b

      - name: Module C - Topics/Timeseries/Insight
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          source .venv/bin/activate
          echo "[INFO] USE_PRO=${USE_PRO} â†’ Module C ì‹¤í–‰(ì›Œí¬í”Œë¡œìš°)"
          python -m src.module_c

      - name: Check C - Validate Insights
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.check_c

      - name: Export signals (trend strength & weak signals)
        shell: bash
        run: |
          source .venv/bin/activate
          python -m scripts.signal_export

      - name: Generate Future Insights (Maturity & Weak Signals)
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          source .venv/bin/activate
          python -m scripts.future_insights

      - name: Module D - Analysis
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          source .venv/bin/activate
          python -m src.module_d

      - name: Check D - Validate Analysis
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.check_d

      - name: Module E - Biz Opportunities
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          source .venv/bin/activate
          python -m src.module_e

      - name: Check E - Validate Biz Opportunities
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.check_e

      - name: Generate Visuals for Report
        shell: bash
        run: |
          source .venv/bin/activate
          python -m scripts.generate_visuals

      - name: Preflight Checks
        shell: bash
        env:
          PREFLIGHT_MIN_DAILY: "1"
          PREFLIGHT_MIN_TOTAL: "1"
          PREFLIGHT_MAX_SPAN:  "400"
        run: |
          set -e
          source .venv/bin/activate
          python -m scripts.preflight

      - name: Module F - Build Report
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.module_f

      - name: Check F - Validate Report
        shell: bash
        run: |
          source .venv/bin/activate
          python -m src.check_f

      # --- ìš”ì•½ ë° ì •ë¦¬ ë‹¨ê³„ ---
      - name: Build Job Summary
        shell: bash
        run: |
          source .venv/bin/activate
          python - <<'PY'
          import json, os
          def load(p, default):
              try:
                  with open(p, encoding="utf-8") as f:
                      return json.load(f)
              except Exception:
                  return default
          ts = load("outputs/trend_timeseries.json", {"daily":[]})
          daily = ts.get("daily", [])
          total = sum(int(x.get("count",0)) for x in daily)
          dr = f"{daily[0]['date']} ~ {daily[-1]['date']}" if daily else "-"
          kw = load("outputs/keywords.json", {"keywords":[]}).get("keywords", [])
          kw = sorted(kw, key=lambda x: x.get("score",0), reverse=True)[:10]
          opp = load("outputs/biz_opportunities.json", {"ideas":[]}).get("ideas", [])[:5]
          lines = []
          lines.append("# Daily Pipeline Summary\n")
          lines.append(f"- ê¸°ê°„: {dr}")
          lines.append(f"- ì´ ê¸°ì‚¬ ìˆ˜: {total}\n")
          lines.append("## Top 10 Keywords")
          lines.append("| Rank | Keyword | Score |")
          lines.append("|---:|---|---:|")
          for i, k in enumerate(kw, 1):
              lines.append(f"| {i} | {k.get('keyword','')} | {round(float(k.get('score',0)),3)} |")
          lines.append("")
          lines.append("## Opportunities (Top 5)")
          if opp:
              for i, it in enumerate(opp, 1):
                  title = it.get('title') or it.get('idea') or '(no title)'
                  lines.append(f"- {i}. {title}")
          else:
              lines.append("- (ë°ì´í„° ì—†ìŒ)")
          txt = "\n".join(lines) + "\n"
          print(txt)
          summ = os.environ.get("GITHUB_STEP_SUMMARY")
          if summ:
              with open(summ, "a", encoding="utf-8") as f:
                  f.write(txt)
          PY

      # ì¼ìë³„ ì•„ì¹´ì´ë¸Œ(KST)
      - name: Prepare outputs daily folder (KST)
        shell: bash
        run: |
          set -e
          DATE_KST=$(TZ=Asia/Seoul date +'%Y-%m-%d')
          TIME_KST=$(TZ=Asia/Seoul date +'%H%M-KST')
          OUTDIR="outputs/daily/${DATE_KST}/${TIME_KST}"
          mkdir -p "${OUTDIR}/fig" "${OUTDIR}/debug" "${OUTDIR}/export"

          # ê¸°ë³¸ ê²°ê³¼ íŒŒì¼ ë³µì‚¬ (json, html, md)
          cp outputs/*.json             "${OUTDIR}/" || true
          cp outputs/*.html             "${OUTDIR}/" || true
          cp outputs/*.md               "${OUTDIR}/" || true

          # ë””ë²„ê·¸ ë©”íƒ€ íŒŒì¼ë“¤ì„ ì˜¬ë°”ë¥¸ ìœ„ì¹˜(debug/)ì—ì„œ ìƒìœ„ í´ë”ë¡œ ë³µì‚¬
          if [ -f outputs/debug/run_meta_b.json ]; then
            cp outputs/debug/run_meta_b.json "${OUTDIR}/"
          fi
          if [ -f outputs/debug/run_meta_c.json ]; then
            cp outputs/debug/run_meta_c.json "${OUTDIR}/"
          fi
          
          # ì„œë¸Œí´ë” ë‚´ìš© ì „ì²´ ë³µì‚¬ (export, fig, debug)
          if [ -d outputs/export ]; then
            cp -r outputs/export/* "${OUTDIR}/export/" || true
          fi
          if [ -d outputs/fig ]; then
            cp -r outputs/fig/* "${OUTDIR}/fig/" || true
          fi
          if [ -d outputs/debug ]; then
            cp -r outputs/debug/* "${OUTDIR}/debug/" || true
          fi
          
          echo "OUTDIR=${OUTDIR}" >> $GITHUB_ENV

      # outputs ì»¤ë°‹/í‘¸ì‹œ
      - name: Commit & Push outputs
        shell: bash
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add outputs/daily
          git commit -m "chore: outputs (KST rotation)" || echo "no changes"
          git pull --rebase --autostash origin ${{ github.ref_name }} || true
          git push origin HEAD:${{ github.ref_name }} || true

      # ì˜¤ë˜ëœ outputs/warehouse ì •ë¦¬ (ìœ ì§€)
      - name: Cleanup old warehouse (main only, keep 90 days)
        if: github.ref_name == 'main'
        shell: bash
        run: |
          set -e
          test -d data/warehouse || exit 0
          find data/warehouse -type f -daystart -mtime +90 -print -delete || true
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A data/warehouse
          git commit -m "chore: cleanup old warehouse (>90d)" || echo "no changes"
          git pull --rebase --autostash origin ${{ github.ref_name }} || true
          git push origin HEAD:${{ github.ref_name }} || true

      - name: Cleanup old outputs (main only, keep 90 days)
        if: github.ref_name == 'main'
        shell: bash
        run: |
          set -e
          test -d outputs/daily || exit 0
          find outputs/daily -mindepth 1 -maxdepth 1 -type d -daystart -mtime +90 -print -exec rm -rf {} \; || true
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A outputs/daily
          git commit -m "chore: cleanup old outputs (>90d)" || echo "no changes"
          git pull --rebase --autostash origin ${{ github.ref_name }} || true
          git push origin HEAD:${{ github.ref_name }} || true
